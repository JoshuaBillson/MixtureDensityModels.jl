<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · MixtureDensityNetworks.jl</title><script data-outdated-warner src="assets/warner.js"></script><link rel="canonical" href="https://JoshuaBillson.github.io/MixtureDensityNetworks.jl/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>MixtureDensityNetworks.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Example"><span>Example</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li><li><a class="tocitem" href="#API"><span>API</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JoshuaBillson/MixtureDensityNetworks.jl/blob/main/docs/src/index.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="MixtureDensityNetworks"><a class="docs-heading-anchor" href="#MixtureDensityNetworks">MixtureDensityNetworks</a><a id="MixtureDensityNetworks-1"></a><a class="docs-heading-anchor-permalink" href="#MixtureDensityNetworks" title="Permalink"></a></h1><p>Mixture Density Networks (MDNs) were first proposed by <a href="https://publications.aston.ac.uk/id/eprint/373/1/NCRG_94_004.pdf">Bishop (1994)</a>. We can think of them as a specialized type of neural network, which are typically employed when our data has a lot of uncertainty or when the relationship between features and labels is one-to-many. Unlike a traditional neural network, which predicts a point-estimate equal to the mode of the learned conditional distribution P(Y|X), an MDN maintains the full condtional distribution by predicting the parameters of a Gaussian Mixture Model (GMM). The multi-modal nature of GMMs are precisely what makes MDNs so well-suited to modeling one-to-many relationships. This package aims to provide a simple interface for defining, training, and deploying MDNs.</p><h2 id="Example"><a class="docs-heading-anchor" href="#Example">Example</a><a id="Example-1"></a><a class="docs-heading-anchor-permalink" href="#Example" title="Permalink"></a></h2><p>First, let&#39;s create our dataset. To properly demonstrate the power of MDNs, we&#39;ll generate a many-to-one dataset where each x-value can map to more than one y-value.</p><pre><code class="language-julia hljs">using Distributions, CairoMakie, MixtureDensityNetworks

const n_samples = 1000

Y = rand(Uniform(-10.5, 10.5), 1, n_samples)
μ = 7sin.(0.75 .* Y) + 0.5 .* Y
X = rand.(Normal.(μ, 1.0))

fig, ax, plt = scatter(X[1,:], Y[1,:], markersize=5)</code></pre><p><img src="figures/Data.png" alt/></p><p>Now we&#39;ll define our model and training parameters. For this example, we construct a network with 2 hidden layers of size 128, 5 Gaussian  mixtures, and we train for 1000 epochs. All other hyperparameters are set to their default values.</p><pre><code class="language-julia hljs">model = MDN(epochs=1000, mixtures=5, layers=[128, 128])</code></pre><p>We can fit our model to our training data by calling <code>fit!(model, X, Y)</code>. This method returns the learning curve, which we plot below.</p><pre><code class="language-julia hljs">lc = fit!(model, X, Y)
fig, _, _ = lines(1:1000, lc, axis=(;xlabel=&quot;Epochs&quot;, ylabel=&quot;Loss&quot;))</code></pre><p><img src="figures/LearningCurve.png" alt/></p><p>Let&#39;s evaluate how well our model learned to replicate our data by plotting both the learned and true distributions. We observe that our model has indeed learned to replicate the true distribution.</p><pre><code class="language-julia hljs">Ŷ = predict(model, X)
fig, ax, plt = scatter(X[1,:], rand.(Ŷ), markersize=3, label=&quot;Predicted Distribution&quot;)
scatter!(ax, X[1,:], Y[1,:], markersize=3, label=&quot;True Distribution&quot;)
axislegend(ax, position=:lt)</code></pre><p><img src="figures/PredictedDistribution.png" alt/></p><p>We can also visualize the conditional distribution predicted by our model at x = -2.0.</p><pre><code class="language-julia hljs">cond = predict(model, reshape([-2.0], (1,1)))[1]
fig = Figure(resolution=(1000, 500))
density(fig[1,1], rand(cond, 10000), npoints=10000)</code></pre><p><img src="figures/ConditionalDistribution.png" alt/></p><p>Below is a script for running the complete example.</p><pre><code class="language-julia hljs">using MixtureDensityNetworks, Distributions, CairoMakie

const n_samples = 1000
const epochs = 1000
const mixtures = 5
const layers = [128, 128]

function main()
    # Generate Data
    Y = rand(Uniform(-10.5, 10.5), 1, n_samples)
    μ = 7sin.(0.75 .* Y) + 0.5 .* Y
    X = rand.(Normal.(μ, 1.0))

    # Create Model
    model = MDN(epochs=epochs, mixtures=mixtures, layers=layers)

    # Fit Model
    lc = fit!(model, X, Y)

    # Plot Learning Curve
    fig, _, _ = lines(1:epochs, lc, axis=(;xlabel=&quot;Epochs&quot;, ylabel=&quot;Loss&quot;))
    save(&quot;LearningCurve.png&quot;, fig)

    # Plot Learned Distribution
    Ŷ = predict(model, X)
    fig, ax, plt = scatter(X[1,:], rand.(Ŷ), markersize=4, label=&quot;Predicted Distribution&quot;)
    scatter!(ax, X[1,:], Y[1,:], markersize=3, label=&quot;True Distribution&quot;)
    axislegend(ax, position=:lt)
    save(&quot;PredictedDistribution.png&quot;, fig)

    # Plot Conditional Distribution
    cond = predict(model, reshape([-2.0], (1,1)))[1]
    fig = Figure(resolution=(1000, 500))
    density(fig[1,1], rand(cond, 10000), npoints=10000)
    save(&quot;ConditionalDistribution.png&quot;, fig)
end

main()</code></pre><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#MixtureDensityNetworks.MDN-Tuple{}"><code>MixtureDensityNetworks.MDN</code></a></li><li><a href="#MixtureDensityNetworks.MDN"><code>MixtureDensityNetworks.MDN</code></a></li><li><a href="#MixtureDensityNetworks.fit!-Tuple{MDN, Matrix{&lt;:Real}, Matrix{&lt;:Real}}"><code>MixtureDensityNetworks.fit!</code></a></li><li><a href="#MixtureDensityNetworks.likelihood_loss-Tuple{Matrix{&lt;:Real}, Matrix{&lt;:Real}, Matrix{&lt;:Real}, Matrix{&lt;:Real}}"><code>MixtureDensityNetworks.likelihood_loss</code></a></li><li><a href="#MixtureDensityNetworks.predict-Tuple{MDN, Matrix{&lt;:Real}}"><code>MixtureDensityNetworks.predict</code></a></li><li><a href="#MixtureDensityNetworks.predict_mean-Tuple{MDN, Matrix{&lt;:Real}}"><code>MixtureDensityNetworks.predict_mean</code></a></li><li><a href="#MixtureDensityNetworks.predict_mode-Tuple{MDN, Matrix{&lt;:Real}}"><code>MixtureDensityNetworks.predict_mode</code></a></li></ul><h2 id="API"><a class="docs-heading-anchor" href="#API">API</a><a id="API-1"></a><a class="docs-heading-anchor-permalink" href="#API" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="MixtureDensityNetworks.MDN" href="#MixtureDensityNetworks.MDN"><code>MixtureDensityNetworks.MDN</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct MDN</code></pre><p>The hyperparameters defining the classical MDN model.</p><p><strong>Parameters</strong></p><ul><li><p><code>mixtures::Int64</code></p></li><li><p><code>layers::Vector{Int64}</code></p></li><li><p><code>η::Float64</code></p></li><li><p><code>epochs::Int64</code></p></li><li><p><code>batchsize::Int64</code></p></li><li><p><code>fitresult::Any</code></p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JoshuaBillson/MixtureDensityNetworks.jl/blob/d274469187cca16d3a45a774dfa9fea7160da18f/src/interface.jl#L1">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MixtureDensityNetworks.MDN-Tuple{}" href="#MixtureDensityNetworks.MDN-Tuple{}"><code>MixtureDensityNetworks.MDN</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">MDN(; mixtures=5, layers=[128], η=1e-3, epochs=1, batchsize=32)</code></pre><p>Defines an MDN model with the given hyperparameters.</p><p><strong>Parameters</strong></p><ul><li><code>mixtures</code>: The number of gaussian mixtures to use in estimating the conditional distribution (default=5).</li><li><code>layers</code>: A vector indicating the number of nodes in each of the hidden layers (default=[128,]).</li><li><code>η</code>: The learning rate to use when training the model (default=1e-3).</li><li><code>epochs</code>: The number of epochs to train the model (default=1).</li><li><code>batchsize</code>: The batchsize to use during training (default=32).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JoshuaBillson/MixtureDensityNetworks.jl/blob/d274469187cca16d3a45a774dfa9fea7160da18f/src/interface.jl#L18-L29">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MixtureDensityNetworks.fit!-Tuple{MDN, Matrix{&lt;:Real}, Matrix{&lt;:Real}}" href="#MixtureDensityNetworks.fit!-Tuple{MDN, Matrix{&lt;:Real}, Matrix{&lt;:Real}}"><code>MixtureDensityNetworks.fit!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">fit!(
    model::MDN,
    X::Matrix{&lt;:Real},
    Y::Matrix{&lt;:Real}
) -&gt; Vector{Float64}
</code></pre><p>Fit the model to the data given by X and Y.</p><p><strong>Parameters</strong></p><ul><li><code>model</code>: The MDN to be trained.</li><li><code>X</code>: A dxn matrix where d is the number of features and n is the number of samples.</li><li><code>Y</code>: A 1xn matrix where n is the number of samples.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JoshuaBillson/MixtureDensityNetworks.jl/blob/d274469187cca16d3a45a774dfa9fea7160da18f/src/interface.jl#L34">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MixtureDensityNetworks.likelihood_loss-Tuple{Matrix{&lt;:Real}, Matrix{&lt;:Real}, Matrix{&lt;:Real}, Matrix{&lt;:Real}}" href="#MixtureDensityNetworks.likelihood_loss-Tuple{Matrix{&lt;:Real}, Matrix{&lt;:Real}, Matrix{&lt;:Real}, Matrix{&lt;:Real}}"><code>MixtureDensityNetworks.likelihood_loss</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">likelihood_loss(
    μ::Matrix{&lt;:Real},
    σ::Matrix{&lt;:Real},
    pi::Matrix{&lt;:Real},
    y::Matrix{&lt;:Real}
) -&gt; Float64
</code></pre><p>Conpute the negative log-likelihood loss for a set of labels <code>y</code> under a Gaussian Mixture Model defined by the parameters <code>μ</code>, <code>σ</code>, and <code>pi</code>.</p><p><strong>Parameters</strong></p><ul><li><code>μ</code>: A mxn matrix of means where m is the number of Gaussian mixtures and n is the number of samples.</li><li><code>σ</code>: A mxn matrix of standard deviations where m is the number of Gaussian mixtures and n is the number of samples.</li><li><code>pi</code>: A mxn matrix of priors where m is the number of Gaussian mixtures and n is the number of samples.</li><li><code>y</code>: A 1xn matrix of labels where n is the number of samples.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JoshuaBillson/MixtureDensityNetworks.jl/blob/d274469187cca16d3a45a774dfa9fea7160da18f/src/losses.jl#L1">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MixtureDensityNetworks.predict-Tuple{MDN, Matrix{&lt;:Real}}" href="#MixtureDensityNetworks.predict-Tuple{MDN, Matrix{&lt;:Real}}"><code>MixtureDensityNetworks.predict</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">predict(
    model::MDN,
    X::Matrix{&lt;:Real}
) -&gt; Vector{Distributions.MixtureModel}
</code></pre><p>Predict the full conditional distribution P(Y|X).</p><p><strong>Parameters</strong></p><ul><li><code>model</code>: The MDN with which we want to generate a prediction.</li><li><code>X</code>: A dxn matrix where d is the number of features and n is the number of samples.</li></ul><p><strong>Returns</strong></p><p>Returns a vector of Distributions.MixtureModel objects representing the conditional distribution for each sample.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JoshuaBillson/MixtureDensityNetworks.jl/blob/d274469187cca16d3a45a774dfa9fea7160da18f/src/interface.jl#L92">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MixtureDensityNetworks.predict_mean-Tuple{MDN, Matrix{&lt;:Real}}" href="#MixtureDensityNetworks.predict_mean-Tuple{MDN, Matrix{&lt;:Real}}"><code>MixtureDensityNetworks.predict_mean</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">predict_mean(
    model::MDN,
    X::Matrix{&lt;:Real}
) -&gt; AbstractVector
</code></pre><p>Predict the mean of the conditional distribution P(Y|X). </p><p><strong>Parameters</strong></p><ul><li><code>model</code>: The MDN with which we want to generate a prediction.</li><li><code>X</code>: A dxn matrix where d is the number of features and n is the number of samples.</li></ul><p><strong>Returns</strong></p><p>Returns a vector of real numbers representing the mean of the conditional distribution P(Y|X) for each sample.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JoshuaBillson/MixtureDensityNetworks.jl/blob/d274469187cca16d3a45a774dfa9fea7160da18f/src/interface.jl#L119">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MixtureDensityNetworks.predict_mode-Tuple{MDN, Matrix{&lt;:Real}}" href="#MixtureDensityNetworks.predict_mode-Tuple{MDN, Matrix{&lt;:Real}}"><code>MixtureDensityNetworks.predict_mode</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">predict_mode(model::MDN, X::Matrix{&lt;:Real}) -&gt; Any
</code></pre><p>Predict the mean of the Gaussian with the largest prior in the conditional distribution P(Y|X). </p><p><strong>Parameters</strong></p><ul><li><code>model</code>: The MDN with which we want to generate a prediction.</li><li><code>X</code>: A dxn matrix where d is the number of features and n is the number of samples.</li></ul><p><strong>Returns</strong></p><p>Returns a vector of real numbers representing the mean of the gaussian with the largest prior for each sample.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JoshuaBillson/MixtureDensityNetworks.jl/blob/d274469187cca16d3a45a774dfa9fea7160da18f/src/interface.jl#L140">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Sunday 2 April 2023 05:49">Sunday 2 April 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
